04 Octubre
    - Creación del repositorio y del proyecto base. https://github.com/DavidGRueda/MWDSP
    - Descarga del subconjunto de problemas. Almacenamiento en /data
    - Creación de la clase Instance. 
        - Array de pesos con la fórmula w(i) = (i mod 200) + 1 (para DIMACS y BHOSLIB)
        - Número de nodos y de aristas. 
        - Matriz de adyacencia. 
        - Se realiza el parser para archivos .clq -> Ahora con un bucle while y un if.
          Opción de ser modificado para ignorar los primeros comentarios y empezar a contar a partir que se encuentra "p", 
          haciendo uso del número de aristas para cerrar el fichero. Preguntar a Jesús, aunque no es algo crítico. 
        - Se baraja el uso de un ArrayList para la lista de adyacencia. Mejor que una LinkedList ya que, para el acceso a un determinado índice,
          tiene una complejidad O(1), aunque la creación sea más costosa (creación no cuenta en tiempo). 
05 Octubre
    - Se termina de desarrollar la lista de adyacecncia con ArrayList. Se comprueba el funcionamiento correcto. 
    - Se construye el parser para archivos .mtx. Se realiza una comprobación de los últimos 3 caracteres del "filename" en la creación
      de la Instancia. 
    - Código encapsulado en varios submétodos fácilmente modificables para evitar código duplicado.
    - Creación de la clase "Solution".
        - Se añaden tanto arrays que contienen todos los datos de forma concreta como una forma optimizada. P.e:
          Para el peso, se tiene un array de los nodos seleccionados y de los pesos (para no tener que acceder a la instancia una y otra vez al
          añadir un nodo concreto), pero también un "totalWeight".
          Para los nodos dominados, en vez de recorrer el array para saber si todos son 1, tener una variable "numDomNodes" 
        - Al añadir un nodo, se deben de marcar aquellos nodos que se dominan al seleccionarlo y añadir el peso.
    - Creación de la clase "RandomBuilder" -> Selecciona nodos aleatorios siempre y los añade a la solución hasta que todos estén dominados. 
13 Octubre
    - Se establece que los casos de uso de DIMACS y BHOSLIB son erróneos (no coinciden con los resultados del paper). Se establece un nuevo
      subconjunto de problemas desde la carpeta T1. 
    - Se crea un nuevo parser por defecto que tratará estas nuevas instancias del problema (se borran las anteriores pero no sus parsers). 
    - Se crea nueva tabla de tiempos con el formato especificado en la tutoría para medir los tiempos más fácilmente. 
      https://docs.google.com/spreadsheets/d/1qn7FTewv3bSMuiCleIF9dv8TshVnmj9Zua-MkyMlK2U/edit?usp=sharing
    - Se rellenan los diferentes datos del algoritmo RandomBuilder. Como conclusión, se aprecia que los grafos con pocos nodos y con gran 
      número de aristas son resueltos con gran eficiencia por el RandomBuilder, pero es pésimo con respecto al resto de grafos en el cálculo
      de la f.o.
14 Octubre
    - Se comienza el desarrollo de la clase GreedyBuilder -> Constructor con algoritmo voraz. 
    - Para evitar que entre en tiempo la creación del array con el número de conexiones que tiene cada nodo, se genera dentro de la instancia (ya que
      no entra en tiempo), evitando así un factor O(n). Se realiza un getter luego en la creación de la solución a partir de la instancia. 
    - Al crear el nuevo constructor voraz, surgen algunas preguntas. Entre ellas:
      - ¿Cómo realizar la actualización de la función objectivo del algoritmo voraz?
      - ¿Cómo reducir la complejidad de la actualización de las conexiones?
      - ¿Es óptimo recorrer bucle varias veces? -> ¿Se puede optimizar el cálculo del criterio voraz?
    - Se crean el número de conexiones, pero deben de ser actualizadas cada vez que uno de los nodos se marque como dominado.
    - Para que sea más rápido, en vez de actualizar las conexiones del nodo seleccionado (si no estaba dominado), se utiliza el bucle de actualización
      de la dominación de sus vecinos para ahorrar un bucle (con una variable booleana). 

22 Octubre
    - Construcción de la clase GraspBuilder -> Greedy Randomized Adaptative Search Procedure. 
    - Complejidad actual del algoritmo -> O(2n), dos bucles for:
      - Uno para calcular todas las funciones objetivo de cada uno de los nodos (si no están seleccionados)
      - Otra para calcular los candidatos que pasan el filtro para luego seleccionar uno de ellos de forma aleatoria. 
    - Se genera una solución por cada uno de los algoritmos, pero luego se modifica para realizar 100 soluciones y tomar la mejor de ellas. 
    - Se itera 4 veces para comprobar resultados con valor alpha = 0.25, 0.5, 0.75 y aleatorio entre (0, 1) para cada iteración de las 100 soluciones. 