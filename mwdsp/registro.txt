04 Octubre
    - Creación del repositorio y del proyecto base. https://github.com/DavidGRueda/MWDSP
    - Descarga del subconjunto de problemas. Almacenamiento en /data
    - Creación de la clase Instance. 
        - Array de pesos con la fórmula w(i) = (i mod 200) + 1 (para DIMACS y BHOSLIB)
        - Número de nodos y de aristas. 
        - Matriz de adyacencia. 
        - Se realiza el parser para archivos .clq -> Ahora con un bucle while y un if.
          Opción de ser modificado para ignorar los primeros comentarios y empezar a contar a partir que se encuentra "p", 
          haciendo uso del número de aristas para cerrar el fichero. Preguntar a Jesús, aunque no es algo crítico. 
        - Se baraja el uso de un ArrayList para la lista de adyacencia. Mejor que una LinkedList ya que, para el acceso a un determinado índice,
          tiene una complejidad O(1), aunque la creación sea más costosa (creación no cuenta en tiempo). 
05 Octubre
    - Se termina de desarrollar la lista de adyacecncia con ArrayList. Se comprueba el funcionamiento correcto. 
    - Se construye el parser para archivos .mtx. Se realiza una comprobación de los últimos 3 caracteres del "filename" en la creación
      de la Instancia. 
    - Código encapsulado en varios submétodos fácilmente modificables para evitar código duplicado.
    - Creación de la clase "Solution".
        - Se añaden tanto arrays que contienen todos los datos de forma concreta como una forma optimizada. P.e:
          Para el peso, se tiene un array de los nodos seleccionados y de los pesos (para no tener que acceder a la instancia una y otra vez al
          añadir un nodo concreto), pero también un "totalWeight".
          Para los nodos dominados, en vez de recorrer el array para saber si todos son 1, tener una variable "numDomNodes" 
        - Al añadir un nodo, se deben de marcar aquellos nodos que se dominan al seleccionarlo y añadir el peso.
    - Creación de la clase "RandomBuilder" -> Selecciona nodos aleatorios siempre y los añade a la solución hasta que todos estén dominados. 
13 Octubre
    - Se establece que los casos de uso de DIMACS y BHOSLIB son erróneos (no coinciden con los resultados del paper). Se establece un nuevo
      subconjunto de problemas desde la carpeta T1. 
    - Se crea un nuevo parser por defecto que tratará estas nuevas instancias del problema (se borran las anteriores pero no sus parsers). 
    - Se crea nueva tabla de tiempos con el formato especificado en la tutoría para medir los tiempos más fácilmente. 
      https://docs.google.com/spreadsheets/d/1qn7FTewv3bSMuiCleIF9dv8TshVnmj9Zua-MkyMlK2U/edit?usp=sharing
    - Se rellenan los diferentes datos del algoritmo RandomBuilder. Como conclusión, se aprecia que los grafos con pocos nodos y con gran 
      número de aristas son resueltos con gran eficiencia por el RandomBuilder, pero es pésimo con respecto al resto de grafos en el cálculo
      de la f.o.
14 Octubre
    - Se comienza el desarrollo de la clase GreedyBuilder -> Constructor con algoritmo voraz. 
    - Para evitar que entre en tiempo la creación del array con el número de conexiones que tiene cada nodo, se genera dentro de la instancia (ya que
      no entra en tiempo), evitando así un factor O(n). Se realiza un getter luego en la creación de la solución a partir de la instancia. 
    - Al crear el nuevo constructor voraz, surgen algunas preguntas. Entre ellas:
      - ¿Cómo realizar la actualización de la función objectivo del algoritmo voraz?
      - ¿Cómo reducir la complejidad de la actualización de las conexiones?
      - ¿Es óptimo recorrer bucle varias veces? -> ¿Se puede optimizar el cálculo del criterio voraz?
    - Se crean el número de conexiones, pero deben de ser actualizadas cada vez que uno de los nodos se marque como dominado.
    - Para que sea más rápido, en vez de actualizar las conexiones del nodo seleccionado (si no estaba dominado), se utiliza el bucle de actualización
      de la dominación de sus vecinos para ahorrar un bucle (con una variable booleana). 

22 Octubre
    - Construcción de la clase GraspBuilder -> Greedy Randomized Adaptative Search Procedure. 
    - Complejidad actual del algoritmo -> O(2n), dos bucles for:
      - Uno para calcular todas las funciones objetivo de cada uno de los nodos (si no están seleccionados)
      - Otra para calcular los candidatos que pasan el filtro para luego seleccionar uno de ellos de forma aleatoria. 
    - Se genera una solución por cada uno de los algoritmos, pero luego se modifica para realizar 100 soluciones y tomar la mejor de ellas. 
    - Se itera 4 veces para comprobar resultados con valor alpha = 0.25, 0.5, 0.75 y aleatorio entre (0, 1) para cada iteración de las 100 soluciones. 
    - Posible hipótesis -> En grafos fuertemente conexos, ¿mucho mejor un alpha alto? ¿Y en poco conexos uno bajo?

23 Noviembre
    - Continuación de la creación de la purga del día anterior. 
    - Se crea la purga en la clase Solution. Se realiza con una pila para almacenar aquellas conexiones que no se quedan
      descubiertas para así no modificar la solución general hasta que no se compruebe que realmente se puede hacer la 
      purga. 
    - También se utiliza un ArrayList auxiliar de tal forma que no se tenga que hacer un remove de la lista final de 
      nodos seleccionados -> Pasar de complejidad O(N) a complejidad O(1) para los nuevos nodos seleccionados.
    - NOTA! SE UTILIZA UN ARRAYLIST ACTUALMENTE PARA ALMACENAR LOS NODOS SELECCIONADOS. PUEDE SER COSTOSO LA OPERACIÓN
      ADD() EN CASO DE QUE SE TENGA QUE AMPLIAR EL ARRAY INTERNO (O(N)) -> POSIBLE MEJORA. LINKEDLIST?

24 Noviembre
    - Se comienza a plantear el uso de sets para almacenar tanto los nodos dominados como los no dominados, ya que las 
      operaciones de add() y remove() en este tipo de estructuras son O(1), al igual que el contains(), por lo que faci-
      lita tanto el acceso para saber si un nodo se encuentra o no en la solución como añadirlo o retirarlo de la misma. 
      Ahora mismo se tiene un array de dominio [0-1] para saber si un nodo se encuentra o no en la solucion. Modificarlo
      evitaría el uso de dos estructuras diferentes para almacenar los nodos seleccionados.
    - Se genera la interfaz principal de la búsqueda local y la concreta de 1xN First Improvement.
    - Se modifica la estructura de los nodos seleccionados a Set tras comprobar sus beneficios sobre el código y facili-
      tar el desarrollo del código de la búsqueda local. 